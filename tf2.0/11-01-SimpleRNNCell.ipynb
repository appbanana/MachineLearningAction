{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 10000\n",
    "max_review_len = 80\n",
    "embedding_len = 100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本预处理\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(10000).batch(batch_size, \n",
    "                                         drop_remainder=True # 如果最后一批次不够128 直接弃掉\n",
    "                                        )\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "        # 初始化 rnn cell的state\n",
    "        self.state0 = [tf.zeros([batch_size, units])]\n",
    "        \n",
    "        # [b, 80] => [b, 80, 100] 每个句子最多80个单词, 每个单词用100维的向量表示\n",
    "        # 嵌入模型把你文本转化为数值型的向量\n",
    "        self.embedding = keras.layers.Embedding(total_words, # 输入维度 目前设置的80维\n",
    "                                                embedding_len, # 每个单词\n",
    "                                                input_length=max_review_len, # 句子长度\n",
    "                                               )\n",
    "        # cell把你一个句子在时间轴上展开 h_dim: 64 \n",
    "        # [b, 80, 100] => [b, 64] \n",
    "        # # units参数就是h_dim, 将100维的单词向量进行信息提取,转化为内部的state, 就是label的状态\n",
    "        self.rnn_cell0 = keras.layers.SimpleRNNCell(units=units, dropout=0.5)\n",
    "        # 从开始到输出层 数据维度的变化 [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        # 总共三层 第一层是嵌入层  第二层是SimpleRNNCell 信息提取层 第三层是输出层 输出预测值\n",
    "        self.out_layer = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        前向传播的计算过程\n",
    "        \n",
    "        net(x) net(x, training=True) :train mode \n",
    "        net(x, training=False): test\n",
    "        dropout 只有在训练模式下起作用 测试模式下不管用\n",
    "        :param inputs: 一句话 [b, 80] b为批次大小, 80 每个句子80个单词\n",
    "        :param training:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        # 嵌入层 [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # rnn cell计算\n",
    "        state0 = self.state0\n",
    "        for word in tf.unstack(x, axis=1): \n",
    "            # unstack 在单词数量的维度上展开 转化成80个[b, 100], [b, 100] 每一个代表一个句子中第一个单词, 第二个单词...\n",
    "            # 在时间轴上 依次计算每个单词的的state, 并把它当做下一次的输入\n",
    "            out, state0 = self.rnn_cell0(word, state0, training)\n",
    "        \n",
    "        # 输出层 [b, 64] => [b, 1]\n",
    "        x = self.out_layer(out)\n",
    "        # 将这个值 转化为概率 P(y is positive | x)\n",
    "        prob = tf.sigmoid(x)\n",
    "        return prob\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "195/195 [==============================] - 16s 85ms/step - loss: 0.5259 - accuracy: 0.6334 - val_loss: 0.4017 - val_accuracy: 0.8204\n",
      "Epoch 2/6\n",
      "195/195 [==============================] - 10s 54ms/step - loss: 0.3311 - accuracy: 0.8526 - val_loss: 0.5318 - val_accuracy: 0.8004\n",
      "Epoch 3/6\n",
      "195/195 [==============================] - 10s 53ms/step - loss: 0.2693 - accuracy: 0.8905 - val_loss: 0.5527 - val_accuracy: 0.8049\n",
      "Epoch 4/6\n",
      "195/195 [==============================] - 11s 58ms/step - loss: 0.2169 - accuracy: 0.9100 - val_loss: 0.5611 - val_accuracy: 0.8058\n",
      "Epoch 5/6\n",
      "195/195 [==============================] - 11s 55ms/step - loss: 0.1522 - accuracy: 0.9338 - val_loss: 0.5130 - val_accuracy: 0.8216\n",
      "Epoch 6/6\n",
      "195/195 [==============================] - 10s 54ms/step - loss: 0.1191 - accuracy: 0.9545 - val_loss: 0.5492 - val_accuracy: 0.8147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3a170668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dim = 64\n",
    "epochs = 6\n",
    "\n",
    "# 建立模型\n",
    "model = MyRNN(h_dim)\n",
    "\n",
    "# 编译 训练\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=tf.losses.BinaryCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 3s 15ms/step - loss: 0.5492 - accuracy: 0.8147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5492052810314374, 0.8147035]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN2(keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN2, self).__init__()\n",
    "        # 初始化 rnn cell的state\n",
    "        self.state0 = [tf.zeros([batch_size, units])]\n",
    "        self.state1 = [tf.zeros([batch_size, units])]\n",
    "\n",
    "        \n",
    "        # [b, 80] => [b, 80, 100] 每个句子最多80个单词, 每个单词用100维的向量表示\n",
    "        # 嵌入模型把你文本转化为数值型的向量\n",
    "        self.embedding = keras.layers.Embedding(total_words, # 输入维度 目前设置的80维\n",
    "                                                embedding_len, # 每个单词\n",
    "                                                input_length=max_review_len, # 句子长度\n",
    "                                               )\n",
    "        # cell把你一个句子在时间轴上展开 h_dim: 64 \n",
    "        # [b, 80, 100] => [b, 64] \n",
    "        # # units参数就是h_dim, 将100维的单词向量进行信息提取,转化为内部的state, 就是label的状态\n",
    "        self.rnn_cell0 = keras.layers.SimpleRNNCell(units=units, dropout=0.5)\n",
    "        # 在增加一层\n",
    "        self.rnn_cell1 = keras.layers.SimpleRNNCell(units=units, dropout=0.5)\n",
    "        \n",
    "        # 从开始到输出层 数据维度的变化 [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        # 总共三层 第一层是嵌入层  第二层是SimpleRNNCell 信息提取层 第三层是输出层 输出预测值\n",
    "        self.out_layer = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        前向传播的计算过程\n",
    "        \n",
    "        net(x) net(x, training=True) :train mode \n",
    "        net(x, training=False): test\n",
    "        dropout 只有在训练模式下起作用 测试模式下不管用\n",
    "        :param inputs: 一句话 [b, 80] b为批次大小, 80 每个句子80个单词\n",
    "        :param training:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        # 嵌入层 [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # rnn cell计算\n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1): \n",
    "            # unstack 在单词数量的维度上展开 转化成80个[b, 100], [b, 100] 每一个代表一个句子中第一个单词, 第二个单词...\n",
    "            # 在时间轴上 依次计算每个单词的的state, 并把它当做下一次的输入\n",
    "            out0, state0 = self.rnn_cell0(word, state0, training)\n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "        \n",
    "        # 输出层 [b, 64] => [b, 1]\n",
    "        x = self.out_layer(out1)\n",
    "        # 将这个值 转化为概率 P(y is positive | x)\n",
    "        prob = tf.sigmoid(x)\n",
    "        return prob\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "195/195 [==============================] - 26s 136ms/step - loss: 0.5919 - accuracy: 0.5714 - val_loss: 0.4396 - val_accuracy: 0.8091\n",
      "Epoch 2/6\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.3907 - accuracy: 0.8227 - val_loss: 0.4567 - val_accuracy: 0.8178\n",
      "Epoch 3/6\n",
      "195/195 [==============================] - 12s 61ms/step - loss: 0.3193 - accuracy: 0.8677 - val_loss: 0.6033 - val_accuracy: 0.7963\n",
      "Epoch 4/6\n",
      "195/195 [==============================] - 13s 66ms/step - loss: 0.2853 - accuracy: 0.8832 - val_loss: 0.6630 - val_accuracy: 0.7903\n",
      "Epoch 5/6\n",
      "195/195 [==============================] - 13s 67ms/step - loss: 0.2436 - accuracy: 0.8957 - val_loss: 0.7888 - val_accuracy: 0.7704\n",
      "Epoch 6/6\n",
      "195/195 [==============================] - 13s 66ms/step - loss: 0.2134 - accuracy: 0.9112 - val_loss: 0.5511 - val_accuracy: 0.8167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3ca9edd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dim = 64\n",
    "epochs = 6\n",
    "\n",
    "# 建立模型\n",
    "model2 = MyRNN2(h_dim)\n",
    "\n",
    "# 编译 训练\n",
    "model2.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=tf.losses.BinaryCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(db_train, epochs=epochs, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 3s 17ms/step - loss: 0.5511 - accuracy: 0.8167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5510787895092597, 0.81666666]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(db_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.SimpleRNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

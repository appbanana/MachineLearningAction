{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考链接 https://blog.csdn.net/yzy_1996/article/details/84618536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #全部行都能输出\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造线性回归数据\n",
    "def gen_line_data(sample_num=100):\n",
    "    \"\"\"\n",
    "    y = 3*x1 + 4*x2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x1 = np.linspace(0, 9, sample_num)\n",
    "    x2 = np.linspace(4, 13, sample_num)\n",
    "    x = np.concatenate(([x1], [x2]), axis=0).T\n",
    "    y = np.dot(x, np.array([3, 4]).T)  # y 列向量\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_line_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_sgd1(samples, y, step_size=0.01, momentum=0.1, max_iter_count=10000):\n",
    "    sample_num, dim = samples.shape\n",
    "    w = np.zeros((dim,), dtype=np.float32)\n",
    "    num_iter = 0\n",
    "    loss = 10\n",
    "    gradient = 0\n",
    "    while loss > 0.001 and num_iter < max_iter_count:\n",
    "        loss = 0\n",
    "        error = np.zeros((dim, ), dtype=np.float32)\n",
    "        \n",
    "        for i in range(sample_num):\n",
    "            pred_y = np.dot(w.T, samples[i])\n",
    "            for j in range(dim):\n",
    "                error[j] += (y[i] - pred_y) * samples[i, j]\n",
    "                gradient = momentum * gradient + step_size * error[j]\n",
    "                w[j] -= gradient\n",
    "                \n",
    "        for i in range(sample_num):\n",
    "            pred_y = np.dot(w.T, samples[i])\n",
    "            loss += (y[i] - pred_y) ** 2\n",
    "        loss = loss / sample_num\n",
    "        \n",
    "        print(\"num_iter: \", num_iter, \"the loss:\", loss)\n",
    "        num_iter += 1\n",
    "    return w\n",
    "                \n",
    "            \n",
    "\n",
    "def m_sgd2(samples, y, step_size=0.01, momentum=0.1, max_iter_count=10000):\n",
    "    sample_num, dim = samples.shape\n",
    "    w = np.zeros((dim,), dtype=np.float32)\n",
    "    num_iter = 0\n",
    "    loss = 10\n",
    "    gradient = 0\n",
    "    while loss > 0.001 and num_iter < max_iter_count:\n",
    "        j = num_iter % sample_num\n",
    "        # 这里相当于 (真实值-预测值)^2\n",
    "        loss = 1 / (2 * sample_num) * np.dot((np.dot(samples, w) - y).T,\n",
    "                                     (np.dot(samples, w) - y))\n",
    "        gradient = momentum * gradient + step_size * (samples[j] *\n",
    "                                                  (np.dot(samples[j], w) - y[j]))\n",
    "        w -= gradient\n",
    "        if num_iter % 50 == 0:\n",
    "            print(\"num_iter: \", num_iter, \"the loss:\", loss)\n",
    "        num_iter += 1\n",
    "    return w\n",
    "              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iter:  0 the loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-inf, -inf], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m_sgd1 有点问题\n",
    "m_sgd1(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iter:  0 the loss: 1296.8409090909092\n",
      "num_iter:  50 the loss: 4.297024202829575\n",
      "num_iter:  100 the loss: 6.242860796965204\n",
      "num_iter:  150 the loss: 3.1087429823291903\n",
      "num_iter:  200 the loss: 4.516464714142729\n",
      "num_iter:  250 the loss: 2.249066899016277\n",
      "num_iter:  300 the loss: 3.267535015957276\n",
      "num_iter:  350 the loss: 1.627117911027282\n",
      "num_iter:  400 the loss: 2.363918273888388\n",
      "num_iter:  450 the loss: 1.1771633833809003\n",
      "num_iter:  500 the loss: 1.7102338216319348\n",
      "num_iter:  550 the loss: 0.8516342264811929\n",
      "num_iter:  600 the loss: 1.2372842647094453\n",
      "num_iter:  650 the loss: 0.6161270093735894\n",
      "num_iter:  700 the loss: 0.8951263655536508\n",
      "num_iter:  750 the loss: 0.44574454126489166\n",
      "num_iter:  800 the loss: 0.6476026934938708\n",
      "num_iter:  850 the loss: 0.3224794666423208\n",
      "num_iter:  900 the loss: 0.4685045058711289\n",
      "num_iter:  950 the loss: 0.23330194216886632\n",
      "num_iter:  1000 the loss: 0.33894086951252406\n",
      "num_iter:  1050 the loss: 0.16878661665828598\n",
      "num_iter:  1100 the loss: 0.24521869583143996\n",
      "num_iter:  1150 the loss: 0.12211095124341922\n",
      "num_iter:  1200 the loss: 0.17741920513374232\n",
      "num_iter:  1250 the loss: 0.0883422910336032\n",
      "num_iter:  1300 the loss: 0.12835055190629405\n",
      "num_iter:  1350 the loss: 0.06391241480102787\n",
      "num_iter:  1400 the loss: 0.09285940020590731\n",
      "num_iter:  1450 the loss: 0.04623805622620513\n",
      "num_iter:  1500 the loss: 0.06717072054477752\n",
      "num_iter:  1550 the loss: 0.033451843303743865\n",
      "num_iter:  1600 the loss: 0.04860016917482241\n",
      "num_iter:  1650 the loss: 0.024201318613780734\n",
      "num_iter:  1700 the loss: 0.035160016393821145\n",
      "num_iter:  1750 the loss: 0.017508836901859077\n",
      "num_iter:  1800 the loss: 0.025436004441702447\n",
      "num_iter:  1850 the loss: 0.01266726305653456\n",
      "num_iter:  1900 the loss: 0.018403006522410177\n",
      "num_iter:  1950 the loss: 0.00916454958495191\n",
      "num_iter:  2000 the loss: 0.013313676146791171\n",
      "num_iter:  2050 the loss: 0.006630235862034639\n",
      "num_iter:  2100 the loss: 0.009631825223329659\n",
      "num_iter:  2150 the loss: 0.004796792141722126\n",
      "num_iter:  2200 the loss: 0.006971190134442749\n",
      "num_iter:  2250 the loss: 0.0034700740027811794\n",
      "num_iter:  2300 the loss: 0.005040717290787652\n",
      "num_iter:  2350 the loss: 0.0025104568529289197\n",
      "num_iter:  2400 the loss: 0.0036468759686323887\n",
      "num_iter:  2450 the loss: 0.0018163652224077803\n",
      "num_iter:  2500 the loss: 0.0026398454453648934\n",
      "num_iter:  2550 the loss: 0.0013140590827770272\n",
      "num_iter:  2600 the loss: 0.0019101991887850872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.9648767, 4.018509 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_sgd2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

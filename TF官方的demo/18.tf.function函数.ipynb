{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, feature_column\n",
    "from sklearn import model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "import PIL.Image as Image\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置项\n",
    "# 这个要放到设置中文之前否则还是小方框\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# 指定默认字体 用来正常显示中文标签\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 解决保存图像是负号'-'显示为方块的问题\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# #全部行都能输出\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "    \"\"\"\n",
    "    捕获异常的辅助代码\n",
    "    \"\"\"\n",
    "    try:\n",
    "        yield\n",
    "    except error_class as e:\n",
    "        print('Caught expected exception \\n  {}: {}'.format(error_class, e))\n",
    "    except Exception as e:\n",
    "        print('Got unexpected exception \\n  {}: {}'.format(type(e), e))\n",
    "    else:\n",
    "        raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
    "        error_class))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function就像op\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a+b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=81, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function 有对应的梯度\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as t:\n",
    "    result = add(v, 1.0)\n",
    "# result = v+1, 对v求导result'(v) = 1\n",
    "t.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=156, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以嵌套函数\n",
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "    return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=231, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=239, shape=(), dtype=float32, numpy=2.2>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tracing with <tf.Variable 'Variable:0' shape=() dtype=string>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=255, shape=(), dtype=string, numpy=b'aa'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.function的多样性\n",
    "@tf.function\n",
    "def double(a):\n",
    "    print(\"Tracing with\", a)\n",
    "    return a + a\n",
    "\n",
    "double(tf.constant(1))\n",
    "print('\\n')\n",
    "double(tf.constant(1.1))\n",
    "print('\\n')\n",
    "double(tf.Variable('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining concrete trace\n",
      "Executing traced function\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n",
      "Using a concrete trace with incompatible types will throw an error\n",
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>: cannot compute __inference_double_261 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_261]\n"
     ]
    }
   ],
   "source": [
    "print(\"Obtaining concrete trace\")\n",
    "double_strings = double.get_concrete_function(tf.TensorSpec(None, dtype=tf.string))\n",
    "print(\"Executing traced function\")\n",
    "print(double_strings(tf.constant(\"a\")))\n",
    "print(double_strings(tf.constant(\"b\")))\n",
    "\n",
    "# 使用不匹配的类型就会抛出异常\n",
    "print(\"Using a concrete trace with incompatible types will throw an error\")\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "    double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "追踪 x Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
      "tf.Tensor([4 7], shape=(2,), dtype=int32)\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>: Python inputs incompatible with input_signature: inputs (([[1, 2], [3, 4]],)), input_signature ((TensorSpec(shape=(None,), dtype=tf.int32, name=None),))\n"
     ]
    }
   ],
   "source": [
    "# 调用graph时只追踪一次 就需要设置input_signature参数\n",
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def next_collatz(x):\n",
    "    print('追踪 x', x)\n",
    "    return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
    "\n",
    "print(next_collatz(tf.constant([1, 2])))\n",
    "with assert_raises(ValueError):\n",
    "    next_collatz([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = 10\n",
      "Tracing with num_steps = 20\n"
     ]
    }
   ],
   "source": [
    "def train_on_step():\n",
    "    pass\n",
    "\n",
    "@tf.function\n",
    "def train(num_steps):\n",
    "    print(\"Tracing with num_steps = {}\".format(num_steps))\n",
    "    for _ in range(num_steps):\n",
    "        train_on_step()\n",
    "\n",
    "# 这虽然会追踪,但是有个问题就是 当参数改变的时候又会在再次追踪 但是生成的图是相同的,这就有点浪费\n",
    "train(num_steps=10)\n",
    "train(num_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = Tensor(\"num_steps:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 这个方法较上面的好处就是 这个方法只会触发一次追踪 \n",
    "# 解决方法:在不影响生成图的情况下,将参数转化为Tensor\n",
    "train(num_steps=tf.constant(10))\n",
    "train(num_steps=tf.constant(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 1\n",
      "Executed with 1\n",
      "Executed with 1\n",
      "Traced with 3\n",
      "Executed with 3\n"
     ]
    }
   ],
   "source": [
    "# tf.function 副作用\n",
    "@tf.function\n",
    "def f(x):\n",
    "    print('Traced with', x)\n",
    "    tf.print(\"Executed with\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python side effect\n",
      "Python side effect\n",
      "Python side effect\n"
     ]
    }
   ],
   "source": [
    "# 你如果在每次触发function的时候都触发Python有关的代码 那么你就需要使用py_function\n",
    "# 注意这段代码和上段代码的区别 这段代码print函数打印了3次 上面的代码print打印了两次\n",
    "# 或者直接使用tf的方法进行观察 eg:tf.Variable.assign, tf.print, and tf.summary\n",
    "external_list = []\n",
    "def side_effect(x):\n",
    "  print('Python side effect')\n",
    "  external_list.append(x)\n",
    "\n",
    "    \n",
    "@tf.function\n",
    "def f(x):\n",
    "    tf.py_function(side_effect, inp=[x], Tout=[])\n",
    "\n",
    "f(1.0)\n",
    "f(1.0)\n",
    "f(3.0)\n",
    "\n",
    "assert len(external_list) == 3\n",
    "# .numpy() call required because py_function casts 1 to tf.constant(1)\n",
    "assert external_list[0].numpy() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.function在生成器和迭代器中会有意想不到的事情发生\n",
    "external_var = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "    external_var.assign_add(next(iterator))\n",
    "    tf.print(\"Value of external_var:\", external_var)\n",
    "\n",
    "iterator = iter([0, 1, 2, 3])\n",
    "# 本来这应该返回0, 1, 2, 3\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n"
     ]
    }
   ],
   "source": [
    "external_var = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "    iterator = iter([0, 1, 2, 3])\n",
    "    external_var.assign_add(next(iterator))\n",
    "    tf.print(\"Value of external_var:\", external_var)\n",
    "\n",
    "iterator = iter([0, 1, 2, 3])\n",
    "# 本来这应该返回0, 1, 2, 3\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 15:17:09.961825 4669924800 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:504: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train([(1, 1), (1, 1)]) contains 8 nodes in its graph\n",
      "train([(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]) contains 32 nodes in its graph\n",
      "train(<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 4 nodes in its graph\n",
      "train(<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 4 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "# 解决上面问题的方案就是把生成器和迭代器放到@tf.function  不是很明白???\n",
    "def measure_graph_size(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "  loss = tf.constant(0)\n",
    "  for x, y in dataset:\n",
    "    loss += tf.abs(y - x) # Some dummy computation.\n",
    "  return loss\n",
    "\n",
    "small_data = [(1, 1)] * 2\n",
    "big_data = [(1, 1)] * 10\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=808, shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatic control dependencies\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "  # a = 4\n",
    "  a.assign(y * b)\n",
    "  # b = b + x * a = 2 + 4 = 6\n",
    "  b.assign_add(x * a)\n",
    "\n",
    "  return a + b\n",
    "\n",
    "f(1.0, 2.0)  # 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-45-73e410646579>:3 f  *\n",
      "        v = tf.Variable(1.0)\n",
      "    /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:262 __call__\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:256 _variable_v2_call\n",
      "        shape=shape)\n",
      "    /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:60 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    /anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:364 invalid_creator_scope\n",
      "        \"tf.function-decorated function tried to create \"\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 每次调用时都会创建一个一个变量 这样的话会报错\n",
    "@tf.function\n",
    "def f(x):\n",
    "  v = tf.Variable(1.0)\n",
    "  v.assign_add(x)\n",
    "  return v\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  f(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=884, shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    v.assign_add(x)\n",
    "    return v\n",
    "\n",
    "f(1.0)\n",
    "f(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.function 中创建变量也是可以的 只要是第一次创建就可以 如下面这个例子中obj.v\n",
    "class C: pass\n",
    "obj = C(); obj.v = None\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "  if obj.v is None:\n",
    "    obj.v = tf.Variable(1.0)\n",
    "  return obj.v.assign_add(x)\n",
    "\n",
    "print(g(1.0))  # 2.0\n",
    "print(g(2.0))  # 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.0, shape=(), dtype=float32)\n",
      "tf.Tensor(36.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "state = []\n",
    "@tf.function\n",
    "def fn(x):\n",
    "  if not state:\n",
    "    state.append(tf.Variable(2.0 * x))\n",
    "    state.append(tf.Variable(state[0] * 3.0))\n",
    "  return state[0] * x * state[1]\n",
    "\n",
    "print(fn(tf.constant(1.0)))\n",
    "print(fn(tf.constant(3.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AutoGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.197801948 0.2193712 0.572006226 0.529604435 0.701354623]\n",
      "[0.195261985 0.215918645 0.51683116 0.485078663 0.605226934]\n",
      "[0.192817643 0.21262458 0.475250542 0.450301707 0.540758491]\n",
      "[0.190463066 0.209477261 0.442431867 0.422146976 0.493561924]\n",
      "[0.188192889 0.206466094 0.415658206 0.398737609 0.457038939]\n",
      "[0.18600218 0.203581482 0.393266439 0.378868312 0.427667797]\n",
      "[0.183886394 0.200814813 0.374172747 0.361724228 0.40337038]\n",
      "[0.181841373 0.198158249 0.357636124 0.346731842 0.3828291]\n",
      "[0.179863244 0.195604667 0.343130112 0.333474 0.365161836]\n",
      "[0.17794843 0.19314757 0.330268949 0.321638882 0.349752545]\n",
      "[0.176093623 0.190781 0.318762392 0.310988039 0.33615607]\n",
      "[0.174295738 0.188499525 0.308387399 0.301335663 0.324041337]\n",
      "[0.17255193 0.186298192 0.298969328 0.292534411 0.313156515]\n",
      "[0.17085956 0.184172392 0.290369093 0.28446579 0.303305954]\n",
      "[0.169216082 0.182117909 0.282474488 0.27703318 0.294335037]\n",
      "[0.167619228 0.180130824 0.275193721 0.270157 0.286119848]\n",
      "[0.16606684 0.178207532 0.268450916 0.263770908 0.278559595]\n",
      "[0.164556861 0.176344678 0.262182802 0.257819176 0.271571428]\n",
      "[0.163087413 0.174539164 0.256336 0.252254575 0.265086442]\n",
      "[0.161656722 0.172788098 0.250865281 0.247036815 0.259046853]\n",
      "[0.160263091 0.1710888 0.24573186 0.242131189 0.253403783]\n",
      "[0.158904955 0.169438764 0.240902364 0.237507716 0.248115569]\n",
      "[0.157580823 0.167835668 0.236347869 0.233140305 0.243146434]\n",
      "[0.156289294 0.166277304 0.232043192 0.229006082 0.238465458]\n",
      "[0.155029073 0.164761618 0.227966249 0.225084975 0.234045789]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1110, shape=(5,), dtype=float32, numpy=\n",
       "array([0.1537989 , 0.16328673, 0.22409761, 0.22135927, 0.22986391],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def tf__f(x):\\n  do_return = False\\n  retval_ = ag__.UndefinedReturnValue()\\n\\n  def loop_test(x_1):\\n    return ag__.converted_call('reduce_sum', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None) > 1\\n\\n  def loop_body(x_1):\\n    ag__.converted_call('print', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None)\\n    x_1 = ag__.converted_call('tanh', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None)\\n    return x_1,\\n  x, = ag__.while_stmt(loop_test, loop_body, (x,))\\n  do_return = True\\n  retval_ = x\\n  cond = ag__.is_undefined_return(retval_)\\n\\n  def get_state():\\n    return ()\\n\\n  def set_state(_):\\n    pass\\n\\n  def if_true():\\n    retval_ = None\\n    return retval_\\n\\n  def if_false():\\n    return retval_\\n  retval_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state)\\n  return retval_\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "  def loop_test(x_1):\n",
      "    return ag__.converted_call('reduce_sum', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None) > 1\n",
      "\n",
      "  def loop_body(x_1):\n",
      "    ag__.converted_call('print', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None)\n",
      "    x_1 = ag__.converted_call('tanh', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None)\n",
      "    return x_1,\n",
      "  x, = ag__.while_stmt(loop_test, loop_body, (x,))\n",
      "  do_return = True\n",
      "  retval_ = x\n",
      "  cond = ag__.is_undefined_return(retval_)\n",
      "\n",
      "  def get_state():\n",
      "    return ()\n",
      "\n",
      "  def set_state(_):\n",
      "    pass\n",
      "\n",
      "  def if_true():\n",
      "    retval_ = None\n",
      "    return retval_\n",
      "\n",
      "  def if_false():\n",
      "    return retval_\n",
      "  retval_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state)\n",
      "  return retval_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 如果你感兴趣你可以查看代码autograph的生成, 他看起来像是汇编\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "print(tf.autograph.to_code(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph: Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tf_cond(f, *args):\n",
    "    g = f.get_concrete_function(*args).graph\n",
    "    if any(node.name == 'cond' for node in g.as_graph_def().node):\n",
    "        print(\"{}({}) uses tf.cond.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "    else:\n",
    "        print(\"{}({}) executes normally.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparam_cond(tf.Tensor([1.], shape=(1,), dtype=float32)) executes normally.\n",
      "maybe_tensor_cond(tf.Tensor(-1, shape=(), dtype=int32)) uses tf.cond.\n",
      "maybe_tensor_cond(-1) executes normally.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def hyperparam_cond(x, training=True):\n",
    "  if training:\n",
    "    x = tf.nn.dropout(x, rate=0.5)\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def maybe_tensor_cond(x):\n",
    "  if x < 0:\n",
    "    x = -x\n",
    "  return x\n",
    "\n",
    "# 这个没有看明白 什么样的情况下node.name == 'cond'\n",
    "test_tf_cond(hyperparam_cond, tf.ones([1], dtype=tf.float32))\n",
    "test_tf_cond(maybe_tensor_cond, tf.constant(-1))\n",
    "test_tf_cond(maybe_tensor_cond, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `then` branch\n",
      "Tracing `else` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1185, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tracing both sides can result in unexpected execution of Python code - \n",
    "# it requires that if one branch creates a tensor used downstream, \n",
    "# the other branch must also create that tensor.\n",
    "# 追踪两边会发生异常 必须要求if分支用downstream创建tensor, 另外一个分支也必须创建tensor\n",
    "# 追踪两边会发生异常 例如下面这个 if...else里面的代码都走了\n",
    "@tf.function\n",
    "def f():\n",
    "    x = tf.constant(1)\n",
    "    if tf.constant(True):\n",
    "        x = x + 1\n",
    "        print('Tracing `then` branch')\n",
    "    else:\n",
    "        x = x - 1\n",
    "        print('Tracing `else` branch')\n",
    "    return x\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dynamically_unrolled(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'while' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.while_loop.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  elif any(node.name == 'ReduceDataset' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.data.Dataset.reduce.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) gets unrolled.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_range() gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_range():\n",
    "  x = 0\n",
    "  for i in range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_tfrange() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "# 这段代码和上面的区别就在tf.range\n",
    "@tf.function\n",
    "def for_in_tfrange():\n",
    "  x = tf.constant(0, dtype=tf.int32)\n",
    "  for i in tf.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_tfrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_tfdataset() uses tf.data.Dataset.reduce.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_tfdataset():\n",
    "  x = tf.constant(0, dtype=tf.int64)\n",
    "  for i in tf.data.Dataset.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_tfdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def while_py_cond():\n",
    "  x = 5\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_tf_cond() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "# 这段代码和下面的代码就在于变量x的定义不同,一个是tensor 一个是普通变量\n",
    "@tf.function\n",
    "def while_tf_cond():\n",
    "  x = tf.constant(5)\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "\n",
    "test_dynamically_unrolled(while_tf_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_py_true_py_break(5) gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_py_true_py_break(x):\n",
    "  while True:  # py true\n",
    "    if x == 0: # py break\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_true_py_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_tf_true_tf_break(5) uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "# 上下两端代码的区别在于 while的循环条件略有不同, tf.constant(True) / True\n",
    "@tf.function\n",
    "def while_tf_true_tf_break(x):\n",
    "  while tf.constant(True): # tf true\n",
    "    if x == 0:  # py break\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_tf_true_tf_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_selection, ensemble, model_selection\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/digit recognizor.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们有四种方法进行特征的选择：过滤法，嵌入法，包装法，降维算法\n",
    "# 过滤法：VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 708)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过VarianceThreshold 剔除方差为0的特征 由下面数据可知 明显减少了很多特征\n",
    "selector = feature_selection.VarianceThreshold()\n",
    "x_var0 = selector.fit_transform(X)\n",
    "x_var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 392)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果我们想要留下一半的特征，我们可以把参数threshold设置特征方差的中位数\n",
    "x_fsvar = feature_selection.VarianceThreshold(threshold=np.median(X.var().values)).fit_transform(X)\n",
    "x_fsvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 685)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果特征是二分类，特征的取值就是伯努利随机变量，这些变量的方差可以计算为 Var = p(1 - p) \n",
    "# p为其中某一个分类特征的概率\n",
    "# 过滤\n",
    "x_bvar = feature_selection.VarianceThreshold(0.8 * (1 - 0.8)).fit_transform(X)\n",
    "x_bvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%timeit` not found.\n"
     ]
    }
   ],
   "source": [
    "# Line magic \n",
    "%%timeit\n",
    "feature_selection.VarianceThreshold(0.8 * (1 - 0.8)).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方差过滤后，到底过滤掉的是噪音还是有效特征，是变好还是变坏呢？我们可以画学习曲线，寻找模型效果最好的点\n",
    "# 但现实中，我们不会这样做，因为这样太耗费时间。我们只会使用阈值为0或者阈值很小的方差进行过滤，\n",
    "# 来消除一些我们明显用不到的特征，然后我们使用更优的特征进选择方法继续消减特征数量\n",
    "# 1）卡方过滤\n",
    "# 2）F检验\n",
    "# 3）互信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) 卡方过滤 是专门针对离散型标签的相对性过滤  卡方过滤是计算每个非负特征和标签之间的卡方统计量，并依照卡方统计量从高到低为特征排名，\n",
    "# 在结合feature_selection.SelectKBest 这个输入评分标准选出前K个分数最高的特征类\n",
    "feature_selection.SelectKBest\n",
    "x_fschi = feature_selection.SelectKBest(score_func=feature_selection.chi2, k=300).fit_transform(x_fsvar, y)\n",
    "x_fschi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.85 s ± 82.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_selection.cross_val_score(ensemble.RandomForestClassifier(n_estimators=10), \n",
    "                                x_fschi, \n",
    "                                y, \n",
    "                                cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 接下来我们看看k的学习曲线\n",
    "scores = []\n",
    "for i in range(200, 400, 10):\n",
    "    x_fschi = feature_selection.SelectKBest(feature_selection.chi2, k=i).fit_transform(x_fsvar, y)\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "    score_mean = model_selection.cross_val_score(clf, x_fschi, y, cv=5).mean()\n",
    "    scores.append(score_mean)\n",
    "plt.plot(range(200, 400, 10), scores)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 945664.84392643 1244766.05139164 1554872.30384525 1834161.78305343\n",
      " 1903618.94085294 1845226.62427198 1602117.23307537  708535.17489837\n",
      "  974050.20513718 1188092.19961931 1319151.43467036 1397847.8836796\n",
      " 1433554.26798015 1429043.15373433 1332663.17213405 1101423.25372261\n",
      "  809989.56940485  519266.71772284  285681.88297156  191589.23696468\n",
      "  902883.1255264  1237265.16042373 1503477.73699155 1625807.41495542\n",
      " 1630206.90922916 1630597.02883804 1633456.72909664 1610816.75571229\n",
      " 1483382.49543886 1256290.1574794   951236.1617682   693192.66191748\n",
      "  532386.96220361  504617.38933715  575090.36046243  501025.03733245\n",
      "  802341.10683194 1078344.8724406  1226540.98318702 1269945.07968831\n",
      " 1221758.57688808 1146535.17810241 1080657.20185303 1079065.30979135\n",
      " 1092222.70610032 1064908.45385716 1023327.00231067  974163.15420165\n",
      "  918857.12860617  861439.52030749  828439.23565047  916454.89464771\n",
      "  989713.58229958  543695.5016699   674691.76755044  708113.57226969\n",
      "  657819.3908855   599159.21961671  576483.60795847  559848.1818137\n",
      "  536985.56062372  561457.57734769  594428.19185935  592414.89830452\n",
      "  587801.84097643  672232.60135169  790511.70530618  866573.70991777\n",
      "  891422.58050934  905163.15191882 1006322.94034634  585209.83598254\n",
      "  699596.88963547  705326.82387203  641105.0929774   632098.97938142\n",
      "  725189.43548604  853879.48154986  863895.50862873  709440.99808713\n",
      "  615099.361498    660082.35138802  662040.13166049  647432.43321103\n",
      "  718070.06251003  868119.93550552  995128.78948214  981295.46383871\n",
      "  888906.74357254  803951.63399892  775220.92445238  802661.20360682\n",
      "  806753.10120013  827660.8911231  1008184.76195542 1212658.65697336\n",
      " 1279652.35847441 1071947.51866571  712579.55021262  708178.91784269\n",
      "  931871.22430817  836155.03350401  781584.17446604  883252.58134165\n",
      " 1015304.18853993 1153480.28062008 1235182.10720641 1110286.29490637\n",
      "  762412.0228271   651475.7374445   659784.45490334  761439.40964843\n",
      "  980458.35707785 1285689.5977369  1412800.83270279 1269424.03486304\n",
      "  844394.53343881  453037.70035635  906205.5333485  1314337.38985735\n",
      "  875502.64893107  848574.25317153 1088364.70535319 1143964.61799576\n",
      " 1231934.57606489 1525266.11466634 1624923.27849511 1120921.66905394\n",
      "  381196.04594987  517011.13080559  840830.08443577 1249668.53527256\n",
      " 1487299.06201808 1440993.69232521 1234157.54433962  891091.32709079\n",
      "  767327.74644144 1767505.95851489 1794612.36340341  843649.64862696\n",
      "  974860.15688277 1282142.9789604  1121437.99502364 1158258.4373389\n",
      " 1803319.16430163 2247538.01212782 1715860.1009172   308268.96279553\n",
      "  670765.24199637 1175840.18589306 1569563.41213805 1615071.70298461\n",
      " 1453812.39367812 1429193.59276003 1469624.15320088 1610038.8334007\n",
      " 2381990.83018419 1684641.44646863  781514.82471784 1136274.26981954\n",
      " 1258505.95202954  900621.20914746 1033026.39393914 2032592.30559197\n",
      " 2688297.40292302 2126052.31008566  477854.94097719 1061876.2951535\n",
      " 1617721.02614334 1859303.87013649 1706658.49975169 1442798.15960511\n",
      " 1497467.99791583 1635633.52918659 1789954.0440811  2042036.97897042\n",
      " 1243975.13567915  847897.40531407 1334491.44036763 1146547.23628072\n",
      "  721408.29456933 1099901.34212844 2234797.26301007 2788060.61506624\n",
      " 2097404.45292914  770825.17396301 1509971.18325275 2008828.59327289\n",
      " 2076128.28182046 1775258.41727455 1374882.05100453 1223860.78474695\n",
      " 1190499.55493678 1469994.89713294 1556218.16894472  936604.6211571\n",
      " 1052799.96220046 1487484.96092392 1096221.91497984  754081.7574313\n",
      " 1308952.47883141 2269151.28497174 2519422.4441161  1816912.55593098\n",
      " 1090497.85622876 1822356.78804369 2192372.5304657  2133745.04961112\n",
      " 1807649.67676254 1420349.92183107 1222343.35267926 1165504.99607627\n",
      " 1500572.78318498 1432663.59271325  890862.82928644 1274280.76943075\n",
      " 1432072.36165076  956997.59590817  888742.14373383 1508163.46238821\n",
      " 2117988.12236915 2054465.38907916 1423918.25987689 1286013.85962749\n",
      " 1972608.25057539 2179634.12755044 1979740.23184782 1717723.16781811\n",
      " 1552275.10457858 1461315.1411536  1494620.94971976 1739520.65681857\n",
      " 1442815.46046628 1014723.34171191 1363794.15539944 1122747.63831017\n",
      "  739634.35332833 1067567.31929299 1667592.5097389  1864455.97854722\n",
      " 1579099.16973703  967688.45447601 1416605.83453248 2062165.61891584\n",
      " 2170645.77302745 1901786.79198259 1733725.85760386 1753508.37671084\n",
      " 1712712.42549789 1733493.582237   1770340.59820148 1310901.04423274\n",
      " 1008023.90988477 1061378.72275934  662457.8217003   729648.40292041\n",
      " 1370253.32454603 1741943.51510473 1593454.39731162 1172442.70958932\n",
      "  671601.50140396  511587.36577997 1454955.01309647 2126817.74478926\n",
      " 2263953.8025206  2028172.33782053 1992515.52928071 2172520.74824953\n",
      " 2035403.53821729 1758624.07224114 1514817.58748747 1002116.10560135\n",
      "  669379.60246184  544978.32282227  576722.03477821 1098371.32650041\n",
      " 1603057.05343338 1612844.96289426 1293107.69776289  917550.19379029\n",
      "  683222.7639966   608782.99701169 1391473.37940334 2082151.30610954\n",
      " 2298916.31712188 2140360.89085296 2070900.53848134 2159471.16950063\n",
      " 1981772.43302263 1521754.51234479 1076334.48566226  610262.09016783\n",
      "  351852.98340462  461487.7601437   878540.35993713 1337597.14727232\n",
      " 1481891.62067955 1342562.57238699 1127940.79389167  958491.4694589\n",
      "  884951.02023249  671520.41386273 1232265.31295026 1877169.85821324\n",
      " 2239501.99047448 2199634.11766741 1930471.52367226 1666073.70450191\n",
      " 1364054.30645472 1000936.25390226  656080.48075838  389810.08772878\n",
      "  340150.21186292  602275.43941511  959623.37641551 1156974.48558905\n",
      " 1135816.98677808 1044294.97185606  992281.03054232  964376.78121192\n",
      "  966024.75721634 1491250.50567589 1970679.86657318 2139321.52912066\n",
      " 1894361.40873889 1368494.5514217   829396.07488768  488455.25931088\n",
      "  331978.08818759  293365.6522867   387474.16211622  600489.80555106\n",
      "  783767.50733716  831013.99296771  768407.80393857  738760.56078587\n",
      "  761413.22072658  781528.79224194  615612.72460389  975765.83585216\n",
      " 1382346.6477236  1684701.13053512 1732335.2436048  1492804.58962318\n",
      " 1144230.23099215  852589.97157847  719215.03719448  675891.53891187\n",
      "  687917.5152402   708292.70911948  673810.32849758  550803.45299243\n",
      "  428370.7943997   384587.47807058  407022.00975206  441201.32284902\n",
      "  661202.45504685  904150.80474087 1098249.34334037 1225055.2730661\n",
      " 1312843.88397644 1325774.40817926 1236093.76813092 1036608.01098297\n",
      "  829620.55626671  654964.88596563  520032.72156302  387948.22204601\n",
      "  273436.39846809  203015.85080751  255471.93956392  389884.80778864\n",
      "  561308.92316732  759511.94695328  942402.80700557 1044698.95132913\n",
      " 1009807.32615993  844407.23356341  695110.21243546  637789.62877943\n",
      "  600582.89899187  519392.9652949   399631.65341907 1006027.89058975\n",
      " 1352052.90333271 1647606.90721159 1761733.4081397  1664096.76785043\n",
      " 1396834.58681766 1159784.3628775  1001178.01359166  847886.28143964]\n",
      "************************************************************************************************************************\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "chivalue, pvalues_chi = feature_selection.chi2(x_fsvar, y)\n",
    "print(chivalue)\n",
    "print('********' * 15)\n",
    "print(pvalues_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chivalue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k取多少？我们想要消除所有的p值大于设定值，比如0.05或0.01的特征\n",
    "k = chivalue.shape[0] - (pvalues_chi > 0.05).sum()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 618.65383492  846.18897012 1115.40617051 1362.3677305  1452.03355369\n",
      " 1381.09095571 1138.26505266  464.29616121  660.00977785  849.66393412\n",
      " 1004.7450309  1124.76177588 1200.99190762 1209.29489877 1110.4944286\n",
      "  854.66183292  577.52063451  342.09729054  178.67397866  118.01145533\n",
      "  612.12261014  899.40904291 1196.17528948 1424.49864852 1569.26556677\n",
      " 1742.49910702 1910.98023795 1969.20520223 1731.37475948 1295.09668012\n",
      "  839.15325001  531.97951763  371.82392681  336.00820537  378.93378743\n",
      "  317.47025479  528.94881012  766.40792176  947.63168717 1086.0472161\n",
      " 1177.72017709 1253.79641973 1344.06961068 1507.33781169 1616.50454434\n",
      " 1512.25864876 1289.65180587 1051.26276412  839.48869386  680.07426932\n",
      "  600.85538567  633.55772663  683.96908509  347.65867784  452.76238211\n",
      "  509.16387684  515.7498157   532.86107778  594.62512658  664.18740444\n",
      "  709.37133696  798.11767931  876.69849088  852.76926441  785.70173347\n",
      "  802.88980095  813.2041131   760.85552527  687.94148028  642.84071735\n",
      "  698.11530217  367.16414289  455.90449427  485.50500277  476.23046034\n",
      "  536.72332365  740.12587382 1041.38089649 1168.8028973   941.91083922\n",
      "  795.72843454  861.29818828  868.19464432  838.80173567  886.26659655\n",
      "  959.12740961  934.56890789  783.1988476   631.01107034  542.02937189\n",
      "  493.83337615  533.27899195  572.34131749  657.20547321  981.66873526\n",
      " 1465.82267956 1756.05831022 1385.28086085  798.73125604  761.40508874\n",
      " 1062.6919609   979.38193965  947.82602644 1085.00522683 1152.13801689\n",
      " 1118.1595422  1021.13086631  812.37823266  509.86857625  411.37986706\n",
      "  430.7150329   545.55866945  829.92259533 1376.4852629  1811.62922878\n",
      " 1601.33613631  898.8719158   417.37765921  895.77244253 1455.38592931\n",
      "  956.2421521   990.1748413  1359.47406197 1279.27992017 1166.80888121\n",
      " 1291.41792351 1263.86987819  787.81807986  237.21811742  333.12552194\n",
      "  621.47324186 1139.04489426 1713.54508435 1823.42451065 1436.53069242\n",
      "  884.19442779  717.63373994 2026.90370414 2219.46450157  943.55587655\n",
      " 1217.29127813 1677.03878308 1193.63540136 1039.56842784 1570.18098323\n",
      " 1878.5600272  1284.78903715  190.02740438  444.17019739  928.80156872\n",
      " 1562.54171587 1940.54801063 1816.57346013 1683.83193784 1619.17496376\n",
      " 1865.78706551 3482.82350415 2326.10253286  990.67999393 1632.46650414\n",
      " 1652.51500198  891.26746579  883.96689508 1805.57103626 2389.97435433\n",
      " 1630.34926872  301.84091297  746.3286491  1394.82469151 2008.19411716\n",
      " 2107.3680475  1767.97892382 1786.08753011 1980.1986791  2509.14739387\n",
      " 3366.13986444 1959.90573326 1299.36608875 2218.28123025 1470.25657381\n",
      "  681.02610086  937.54741741 2037.45812231 2518.68810085 1583.0009463\n",
      "  509.76276636 1139.21364745 1881.71834116 2351.30851824 2175.48525458\n",
      " 1624.49647062 1399.44534221 1440.98664744 2229.25720739 2764.00452882\n",
      " 1633.74258116 1870.29253742 2628.79930504 1367.31440177  707.38857243\n",
      " 1150.06936228 2089.08213594 2185.00557858 1318.14722036  747.37697661\n",
      " 1453.94015412 2116.40726513 2399.53090598 2143.53519978 1651.89817908\n",
      " 1414.71662551 1481.62100314 2468.21266727 2666.18025642 1520.6400065\n",
      " 2223.14029953 2271.07109628 1111.06997494  844.31183874 1388.60413626\n",
      " 1917.10207189 1667.61400215  996.09054823  907.80926355 1607.70263546\n",
      " 2085.21461056 2073.68356276 1880.26929744 1756.40165025 1716.45478479\n",
      " 1964.08537105 2796.13761562 2413.09378391 1543.01310963 2118.10377396\n",
      " 1475.29541488  783.59003763 1040.65400476 1582.46200024 1617.32566033\n",
      " 1188.24554305  642.2665701  1011.30241064 1725.70185142 2067.20755476\n",
      " 1893.35116837 1795.96538455 1922.58627318 1951.69309645 2115.44871238\n",
      " 2479.27958039 1809.12095649 1330.8686207  1396.29767244  741.9063402\n",
      "  751.14036409 1410.18529816 1677.6595494  1308.77910167  836.77047561\n",
      "  430.93133677  313.888671   1039.31894918 1811.68171256 2191.69964967\n",
      " 2035.63638826 2114.65218363 2511.27142071 2363.46743373 2053.7687027\n",
      " 1865.84769096 1202.94179711  793.61414555  633.71267282  636.18282736\n",
      " 1218.61245591 1712.62901816 1484.60290068  996.06129466  626.13659134\n",
      "  441.56356583  374.08815796  983.21640593 1764.93014215 2264.93587233\n",
      " 2262.87269162 2323.50890468 2611.66920897 2387.45723028 1763.5696083\n",
      " 1256.32165954  704.77285945  406.94580935  548.06969664 1051.50016486\n",
      " 1542.11172909 1494.38472469 1130.61174365  823.84437277  650.69506052\n",
      "  594.18011033  415.73313115  853.97575783 1548.7167469  2204.00694989\n",
      " 2444.69535795 2267.62871155 2003.69161124 1643.94961527 1202.35520102\n",
      "  804.18805494  483.32932365  420.99263006  750.06949525 1136.32227345\n",
      " 1202.49476981  990.75097727  791.03016258  692.46641159  653.96372577\n",
      "  647.90433225 1149.80460733 1826.54973661 2361.75564926 2313.09139096\n",
      " 1694.26613916 1012.97938867  608.4174945   432.07115684  383.54620406\n",
      "  487.70312805  698.78061024  797.0763827   714.70722998  574.2849126\n",
      "  507.5143557   508.77434021  510.36884435  404.13860698  686.31274396\n",
      " 1103.81003251 1590.83695172 1912.74984902 1832.62220523 1482.39046946\n",
      " 1142.10827805  968.65089356  860.24853405  780.75215696  696.78170045\n",
      "  567.41403081  403.59649375  284.91007929  245.59060983  255.97458001\n",
      "  293.6787996   460.46868009  687.29383613  940.06512113 1205.58777055\n",
      " 1485.37178744 1623.12886955 1488.04856361 1119.91615126  770.06544455\n",
      "  530.6398126   376.66549502  258.05875548  172.20323661  123.79865884\n",
      "  160.44132806  249.15104257  374.15221131  544.73535425  727.78945347\n",
      "  853.98680046  819.19801306  656.55547718  510.87851723  445.09613969\n",
      "  401.25608847  333.48574029  243.88699402  645.9545719   920.3259526\n",
      " 1196.07900013 1308.12260763 1218.37705687  996.41501921  792.59409228\n",
      "  663.47516843  550.14745143]\n",
      "***************************************************************************************************************************************\n",
      "[0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 4.71193533e-220\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 3.26083326e-322 5.24336441e-231 4.04009647e-300 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "# 2) F检验 又称方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法。\n",
    "# feature_selection.f_classif  用于分类\n",
    "# feature_selection.f_regression 用于回归\n",
    "F, pvalues_f = feature_selection.f_classif(x_fsvar, y)\n",
    "print(F)\n",
    "print('*********' * 15)\n",
    "print(pvalues_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = F.shape[0] - (pvalues_f > 0.05).sum()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) 互信息法是用来捕捉每个特征与标签特征之间的任意关系的过滤方法 与F检验相似 \n",
    "# 返回一个估计量在[0, 1]之间取值，为0表示两个变量独立，为1表示两个变量完全相关\n",
    "result = feature_selection.mutual_info_classif(x_fsvar, y)\n",
    "k = result.shape[0] - sum(result <= 0)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, feature_column\n",
    "from sklearn import model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "import PIL.Image as Image\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置项\n",
    "# 这个要放到设置中文之前否则还是小方框\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# 指定默认字体 用来正常显示中文标签\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 解决保存图像是负号'-'显示为方块的问题\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# #全部行都能输出\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5) 5\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
      "[<tf.Variable 'my_layer_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
      "array([[-0.5222734 , -0.35850587,  0.30134052,  0.29253757, -0.53505194,\n",
      "        -0.53600067,  0.36402172,  0.23172945, -0.2801789 , -0.30622697],\n",
      "       [ 0.14803815,  0.2647987 ,  0.33990455,  0.41787618,  0.253309  ,\n",
      "         0.02150285, -0.19001603,  0.2552945 ,  0.11901969, -0.5368032 ],\n",
      "       [ 0.24577576, -0.14686516, -0.19569522,  0.11464286,  0.45634454,\n",
      "         0.04580432,  0.4151029 , -0.17807671,  0.07223165,  0.6227421 ],\n",
      "       [ 0.06573921,  0.39409167, -0.07556933,  0.3521979 , -0.4884317 ,\n",
      "         0.5813101 , -0.20316291,  0.2945698 ,  0.12250668,  0.3052464 ],\n",
      "       [ 0.06508088, -0.20749551,  0.0940544 ,  0.24016804, -0.10095108,\n",
      "         0.445589  ,  0.14860874, -0.47864577, -0.2748164 ,  0.41983622]],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# 自定义layer层 需要自己实现下面三个方法  \n",
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyLayer, self).__init__()\n",
    "        # 下面就可以执行你自己从操作\n",
    "        self.num_outputs = num_outputs\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(input_shape, input_shape[-1])\n",
    "        self.kernel = self.add_variable('kernel', shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        # 下面可以自己想要的操作\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "    \n",
    "# \n",
    "my_layer = MyLayer(10)\n",
    "print(my_layer(tf.zeros([10, 5])))\n",
    "print(my_layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=466, shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义模型 模型是有很多layer组成的  如上所示\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(MyModel, self).__init__(name='jqc')\n",
    "        print('-------========-----')\n",
    "        print(filters)\n",
    "        print('-----******-------')\n",
    "        filters1, filters2, filters3 = filters\n",
    "        \n",
    "        self.conv2a = keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2b = keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2c = keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        \n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # 前一项的输出当做后一项的输入\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------========-----\n",
      "[1, 2, 3]\n",
      "-----******-------\n",
      "tf.Tensor(\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]], shape=(1, 2, 3, 3), dtype=float32)\n",
      "['jqc/conv2d_6/kernel:0', 'jqc/conv2d_6/bias:0', 'jqc/batch_normalization_6/gamma:0', 'jqc/batch_normalization_6/beta:0', 'jqc/conv2d_7/kernel:0', 'jqc/conv2d_7/bias:0', 'jqc/batch_normalization_7/gamma:0', 'jqc/batch_normalization_7/beta:0', 'jqc/conv2d_8/kernel:0', 'jqc/conv2d_8/bias:0', 'jqc/batch_normalization_8/gamma:0', 'jqc/batch_normalization_8/beta:0']\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(1, [1, 2, 3])\n",
    "print(model(tf.zeros([1, 2, 3, 3])))\n",
    "print([x.name for x in model.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
